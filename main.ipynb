{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7843142,"sourceType":"datasetVersion","datasetId":4598363},{"sourceId":6883298,"sourceType":"datasetVersion","datasetId":3954721}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"aafe08c1","cell_type":"markdown","source":"# Spam/Jailbreak Classification","metadata":{}},{"id":"2cc6f56d","cell_type":"markdown","source":"---","metadata":{}},{"id":"34285d6a","cell_type":"markdown","source":"## Dependencies","metadata":{}},{"id":"05f6c012","cell_type":"markdown","source":"### Modules","metadata":{}},{"id":"625b99bf","cell_type":"code","source":"%pip install fastai","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"14fd29c4","cell_type":"code","source":"%pip install torch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a8175e02","cell_type":"code","source":"%pip install transformers","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6d77f79d","cell_type":"code","source":"%pip install datasets","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"58094829","cell_type":"code","source":"%pip install tokenizers","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"dbaad766","cell_type":"code","source":"%pip install scikit-learn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"fe56c459","cell_type":"code","source":"%pip install matplotlib","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e0c32b0d","cell_type":"code","source":"%pip install spacy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c13f77be","cell_type":"code","source":"%pip install evaluate","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"42c6b210","cell_type":"code","source":"%pip install accelerate","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"420228d9","cell_type":"markdown","source":"### Imports","metadata":{}},{"id":"28831d0c","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom fastai.text.all import *\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\nfrom datasets import Dataset, DatasetDict\nimport numpy as np\nimport evaluate\nimport os","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:46:35.451560Z","iopub.execute_input":"2025-08-07T09:46:35.452188Z","iopub.status.idle":"2025-08-07T09:47:07.111628Z","shell.execute_reply.started":"2025-08-07T09:46:35.452153Z","shell.execute_reply":"2025-08-07T09:47:07.111020Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-08-07 09:46:53.760338: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754560013.953079      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754560014.009483      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"id":"90ebf3ce","cell_type":"markdown","source":"---","metadata":{}},{"id":"e2f53494","cell_type":"markdown","source":"## Data","metadata":{}},{"id":"46ac66b2","cell_type":"markdown","source":"190K+ Spam | Ham Email Dataset for Classification: https://www.kaggle.com/datasets/meruvulikith/190k-spam-ham-email-dataset-for-classification\n\nEmails for spam or ham classification (Trec 2007): https://www.kaggle.com/datasets/bayes2003/emails-for-spam-or-ham-classification-trec-2007?select=email_text.csv","metadata":{}},{"id":"7ffc409f","cell_type":"markdown","source":"### Filtering","metadata":{}},{"id":"8275e13b","cell_type":"code","source":"directory = \"data\"\ntry:\n    os.mkdir(directory)\n    print(f\"Directory '{directory}' created successfully.\")\nexcept FileExistsError:\n    print(f\"Directory '{directory}' already exists.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T09:47:29.964834Z","iopub.execute_input":"2025-08-07T09:47:29.966000Z","iopub.status.idle":"2025-08-07T09:47:29.970515Z","shell.execute_reply.started":"2025-08-07T09:47:29.965965Z","shell.execute_reply":"2025-08-07T09:47:29.969841Z"}},"outputs":[{"name":"stdout","text":"Directory 'data' created successfully.\n","output_type":"stream"}],"execution_count":3},{"id":"f1fa8a8a","cell_type":"markdown","source":"Download 2 datasets into \"data\" folder","metadata":{}},{"id":"2cb2d475","cell_type":"code","source":"# df_a = pd.read_csv(\"data/email_text.csv\")\n# df_b = pd.read_csv(\"data/spam_Emails_data.csv\")\n\n#kaggle \ndf_a = pd.read_csv(\"/kaggle/input/emails-for-spam-or-ham-classification-trec-2007/email_text.csv\")\ndf_b = pd.read_csv(\"/kaggle/input/190k-spam-ham-email-dataset-for-classification/spam_Emails_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:51:45.553889Z","iopub.execute_input":"2025-08-07T09:51:45.554744Z","iopub.status.idle":"2025-08-07T09:51:50.574335Z","shell.execute_reply.started":"2025-08-07T09:51:45.554716Z","shell.execute_reply":"2025-08-07T09:51:50.573566Z"},"trusted":true},"outputs":[],"execution_count":7},{"id":"15d9be6a","cell_type":"code","source":"df_b['label'] = df_b['label'].map({\"Spam\": 1, \"Ham\": 0})","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:51:53.420583Z","iopub.execute_input":"2025-08-07T09:51:53.420862Z","iopub.status.idle":"2025-08-07T09:51:53.441829Z","shell.execute_reply.started":"2025-08-07T09:51:53.420841Z","shell.execute_reply":"2025-08-07T09:51:53.441033Z"},"trusted":true},"outputs":[],"execution_count":8},{"id":"ca778a39","cell_type":"code","source":"df_b['label'].unique()","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:51:57.424162Z","iopub.execute_input":"2025-08-07T09:51:57.424756Z","iopub.status.idle":"2025-08-07T09:51:57.433761Z","shell.execute_reply.started":"2025-08-07T09:51:57.424730Z","shell.execute_reply":"2025-08-07T09:51:57.433165Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array([1, 0])"},"metadata":{}}],"execution_count":9},{"id":"ae897513","cell_type":"code","source":"merged = pd.concat([df_a[['label', 'text']], df_b[['label', 'text']]], ignore_index=True)\nmerged","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:51:58.910062Z","iopub.execute_input":"2025-08-07T09:51:58.910977Z","iopub.status.idle":"2025-08-07T09:51:58.950006Z","shell.execute_reply.started":"2025-08-07T09:51:58.910940Z","shell.execute_reply":"2025-08-07T09:51:58.949347Z"},"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"        label  \\\n0           1   \n1           0   \n2           1   \n3           1   \n4           1   \n...       ...   \n247515      0   \n247516      1   \n247517      0   \n247518      1   \n247519      0   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           text  \n0                                                                                                                                                                                                                                                                                                                                                                                                                                                              do you feel the pressure to perform and not rising to the occasion try v ia gr a your anxiety will be a thing of the past and you will be back to your old self   \n1       hi i've just updated from the gulus and i check on other mirrors it seems there is a little typo in debian readme file example http gulus usherbrooke ca debian readme ftp ftp fr debian org debian readme testing or lenny access this release through dists testing the current tested development snapshot is named etch packages which have been tested in unstable and passed automated tests propogate to this release etch should be replace by lenny like in the readme html yan morin consultant en logiciel libre yan morin savoirfairelinux com escapenumber escapenumber escapenumber to unsubscribe ema...  \n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         mega authenticv i a g r a discount pricec i a l i s discount pricedo not miss it click here http www moujsjkhchum com  \n3       hey billy it was really fun going out the other night and talking while we were out you said that you felt insecure about your manhood i noticed in the toilets you were quite small in that area but not to worry that website that i was telling you about is my secret weapon to an extra escapenumber inches trust me girls love bigger ones i've had escapenumber times as many chicks since i used these pills a year ago the package i used was the escapenumber month supply one and its worth every cent and more the website is http ctmay com ring me on the weekend and we will go out and drink again a...  \n4       system of the home it will have the capabilities to be linked far as i know and what i am doing within it as a part of it so with respect to the affects of technology on society we have science ad agencies are cashin g in on its' commerciality and photographs and paint on electronic canvases it still seems like silence white out black out lights out it didn't happen although far from p erfect especially in that it precludes a vast explanation for this i can' t understand how people can rely so avant gardes of the art world additionally writers and lawyers yet to re ach its full potential i...  \n...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ...  \n247515  on escapenumber escapenumber escapenumber rob dixon wrote snip for my elem doc firstchild elem elem elem nextsibling snip i covered that in my earlier email weirder stuff that you only tend to see people coming from a c background do for my node head node node node next but in perl it is rarely necessary to do this sort of loop since most functions return a list that can be iterated over using for for my node head nodes in this case your module should include a children method for my elem doc children or a true iterator my iter doc child iter while my elem iter next if it doesn't then bug ...  \n247516                  we have everything you need escapelong cialescapenumbers sescapenumberft tescapenumberbs vescapenumberagra sescapenumberft tescapenumberbs cialescapenumbers vescapenumberagra levescapenumbertra propecescapenumbera valescapenumberum xanescapenumberx ambescapenumberen zybescapenumbern atarescapenumberx atescapenumbervan carescapenumbersoma ultrescapenumberm escapelong lipescapenumbertor merescapenumberdia zocescapenumberr nescapenumberrvasc we respect your privacy we guarantee you a total anonymity of your escapenumberrder visit us escapelong inc online at http www electioo com   \n247517  hi quick question say i have a date variable in a data frame or matrix and i'd like to preserve the date format when using write table however when i export the data i get the generic number underlying the date not the date per se and a number such as escapenumber escapenumber etc are not meaningful in excel is there any way i can preserve the format of a date on writing into a text file tia and best tir r help stat math ethz ch mailing list https stat ethz ch mailman listinfo r help please do read the posting guide http www r project org posting guide html and provide commented minimal se...  \n247518                                                                                                                                                                                thank you for your loan request which we recieved on escapenumber escapenumber escapenumber we'd like to inform you that we are accepting your application bad credit ok we are ready to give you a escapenumber escapenumber loan for a low month payment approval process will take only escapenumber minute please visit the confirmation link below and fill out our short escapenumber second form http www fastrefi biz a grabadora  \n247519  this is an automatically generated delivery status notification your message has been successfully relayed to the following recipients but the requested delivery status notifications may not be generated by the destination paulconnolly llgm com escapelong aol com ashley brown harvard edu inline attachment follows from to ashley brown harvard edu escapelong aol com paulconnolly llgm com cc roan michael date friday october escapenumber escapenumber escapenumber escapenumber escapenumber gmt subject ashley we would prefer given the schedules to hold a conference call on wednesday pm with a gr...  \n\n[247520 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>do you feel the pressure to perform and not rising to the occasion try v ia gr a your anxiety will be a thing of the past and you will be back to your old self</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>hi i've just updated from the gulus and i check on other mirrors it seems there is a little typo in debian readme file example http gulus usherbrooke ca debian readme ftp ftp fr debian org debian readme testing or lenny access this release through dists testing the current tested development snapshot is named etch packages which have been tested in unstable and passed automated tests propogate to this release etch should be replace by lenny like in the readme html yan morin consultant en logiciel libre yan morin savoirfairelinux com escapenumber escapenumber escapenumber to unsubscribe ema...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>mega authenticv i a g r a discount pricec i a l i s discount pricedo not miss it click here http www moujsjkhchum com</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>hey billy it was really fun going out the other night and talking while we were out you said that you felt insecure about your manhood i noticed in the toilets you were quite small in that area but not to worry that website that i was telling you about is my secret weapon to an extra escapenumber inches trust me girls love bigger ones i've had escapenumber times as many chicks since i used these pills a year ago the package i used was the escapenumber month supply one and its worth every cent and more the website is http ctmay com ring me on the weekend and we will go out and drink again a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>system of the home it will have the capabilities to be linked far as i know and what i am doing within it as a part of it so with respect to the affects of technology on society we have science ad agencies are cashin g in on its' commerciality and photographs and paint on electronic canvases it still seems like silence white out black out lights out it didn't happen although far from p erfect especially in that it precludes a vast explanation for this i can' t understand how people can rely so avant gardes of the art world additionally writers and lawyers yet to re ach its full potential i...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>247515</th>\n      <td>0</td>\n      <td>on escapenumber escapenumber escapenumber rob dixon wrote snip for my elem doc firstchild elem elem elem nextsibling snip i covered that in my earlier email weirder stuff that you only tend to see people coming from a c background do for my node head node node node next but in perl it is rarely necessary to do this sort of loop since most functions return a list that can be iterated over using for for my node head nodes in this case your module should include a children method for my elem doc children or a true iterator my iter doc child iter while my elem iter next if it doesn't then bug ...</td>\n    </tr>\n    <tr>\n      <th>247516</th>\n      <td>1</td>\n      <td>we have everything you need escapelong cialescapenumbers sescapenumberft tescapenumberbs vescapenumberagra sescapenumberft tescapenumberbs cialescapenumbers vescapenumberagra levescapenumbertra propecescapenumbera valescapenumberum xanescapenumberx ambescapenumberen zybescapenumbern atarescapenumberx atescapenumbervan carescapenumbersoma ultrescapenumberm escapelong lipescapenumbertor merescapenumberdia zocescapenumberr nescapenumberrvasc we respect your privacy we guarantee you a total anonymity of your escapenumberrder visit us escapelong inc online at http www electioo com</td>\n    </tr>\n    <tr>\n      <th>247517</th>\n      <td>0</td>\n      <td>hi quick question say i have a date variable in a data frame or matrix and i'd like to preserve the date format when using write table however when i export the data i get the generic number underlying the date not the date per se and a number such as escapenumber escapenumber etc are not meaningful in excel is there any way i can preserve the format of a date on writing into a text file tia and best tir r help stat math ethz ch mailing list https stat ethz ch mailman listinfo r help please do read the posting guide http www r project org posting guide html and provide commented minimal se...</td>\n    </tr>\n    <tr>\n      <th>247518</th>\n      <td>1</td>\n      <td>thank you for your loan request which we recieved on escapenumber escapenumber escapenumber we'd like to inform you that we are accepting your application bad credit ok we are ready to give you a escapenumber escapenumber loan for a low month payment approval process will take only escapenumber minute please visit the confirmation link below and fill out our short escapenumber second form http www fastrefi biz a grabadora</td>\n    </tr>\n    <tr>\n      <th>247519</th>\n      <td>0</td>\n      <td>this is an automatically generated delivery status notification your message has been successfully relayed to the following recipients but the requested delivery status notifications may not be generated by the destination paulconnolly llgm com escapelong aol com ashley brown harvard edu inline attachment follows from to ashley brown harvard edu escapelong aol com paulconnolly llgm com cc roan michael date friday october escapenumber escapenumber escapenumber escapenumber escapenumber gmt subject ashley we would prefer given the schedules to hold a conference call on wednesday pm with a gr...</td>\n    </tr>\n  </tbody>\n</table>\n<p>247520 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"id":"44f0920f","cell_type":"code","source":"merged['label'].unique()","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:52:02.575470Z","iopub.execute_input":"2025-08-07T09:52:02.575734Z","iopub.status.idle":"2025-08-07T09:52:02.581885Z","shell.execute_reply.started":"2025-08-07T09:52:02.575715Z","shell.execute_reply":"2025-08-07T09:52:02.581193Z"},"trusted":true},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"array([1, 0])"},"metadata":{}}],"execution_count":11},{"id":"970e172f","cell_type":"code","source":"merged['text'].unique().shape","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:52:03.707678Z","iopub.execute_input":"2025-08-07T09:52:03.707933Z","iopub.status.idle":"2025-08-07T09:52:03.949998Z","shell.execute_reply.started":"2025-08-07T09:52:03.707914Z","shell.execute_reply":"2025-08-07T09:52:03.949284Z"},"trusted":true},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(193849,)"},"metadata":{}}],"execution_count":12},{"id":"838c7f67","cell_type":"code","source":"merged = merged.drop_duplicates().reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:52:05.783456Z","iopub.execute_input":"2025-08-07T09:52:05.784019Z","iopub.status.idle":"2025-08-07T09:52:05.905900Z","shell.execute_reply.started":"2025-08-07T09:52:05.783996Z","shell.execute_reply":"2025-08-07T09:52:05.905341Z"},"trusted":true},"outputs":[],"execution_count":13},{"id":"fa2cf3bd","cell_type":"code","source":"merged = merged.dropna(subset=['text']).reset_index(drop=True)\nmerged = merged.drop_duplicates(subset=['text']).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:52:07.489044Z","iopub.execute_input":"2025-08-07T09:52:07.489726Z","iopub.status.idle":"2025-08-07T09:52:07.577985Z","shell.execute_reply.started":"2025-08-07T09:52:07.489702Z","shell.execute_reply":"2025-08-07T09:52:07.577451Z"},"trusted":true},"outputs":[],"execution_count":14},{"id":"114f99a6","cell_type":"code","source":"merged.to_csv(\"data/merged_spam_ham.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T09:52:09.304723Z","iopub.execute_input":"2025-08-07T09:52:09.305406Z","iopub.status.idle":"2025-08-07T09:52:18.363132Z","shell.execute_reply.started":"2025-08-07T09:52:09.305380Z","shell.execute_reply":"2025-08-07T09:52:18.362206Z"}},"outputs":[],"execution_count":15},{"id":"9629f2e1","cell_type":"markdown","source":"### Splitting","metadata":{}},{"id":"aaf78eb6","cell_type":"code","source":"train_val, test = train_test_split(\n    merged,\n    train_size=0.9,\n    stratify=merged['label'],  \n    shuffle=True,\n    random_state=42\n)\ntrain, val = train_test_split(\n    train_val,\n    train_size=0.8,\n    stratify=train_val['label'],  \n    shuffle=True,\n    random_state=42\n)\n\ntrain = train.reset_index(drop=True) #72%\nval = val.reset_index(drop=True) #18%\ntest = test.reset_index(drop=True) #10%\n","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:52:32.121946Z","iopub.execute_input":"2025-08-07T09:52:32.122661Z","iopub.status.idle":"2025-08-07T09:52:32.274157Z","shell.execute_reply.started":"2025-08-07T09:52:32.122636Z","shell.execute_reply":"2025-08-07T09:52:32.273421Z"},"trusted":true},"outputs":[],"execution_count":16},{"id":"90523c69","cell_type":"code","source":"directory = \"filtered_data\"\ntry:\n    os.mkdir(directory)\n    print(f\"Directory '{directory}' created successfully.\")\nexcept FileExistsError:\n    print(f\"Directory '{directory}' already exists.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T09:52:35.002818Z","iopub.execute_input":"2025-08-07T09:52:35.003325Z","iopub.status.idle":"2025-08-07T09:52:35.008112Z","shell.execute_reply.started":"2025-08-07T09:52:35.003276Z","shell.execute_reply":"2025-08-07T09:52:35.007484Z"}},"outputs":[{"name":"stdout","text":"Directory 'filtered_data' created successfully.\n","output_type":"stream"}],"execution_count":17},{"id":"48fa1798","cell_type":"code","source":"train.to_csv(\"filtered_data/spam_ham_train.csv\", index=False)\nval.to_csv(\"filtered_data/spam_ham_val.csv\", index=False)\ntest.to_csv(\"filtered_data/spam_ham_test.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T09:52:37.304824Z","iopub.execute_input":"2025-08-07T09:52:37.305096Z","iopub.status.idle":"2025-08-07T09:52:46.458935Z","shell.execute_reply.started":"2025-08-07T09:52:37.305077Z","shell.execute_reply":"2025-08-07T09:52:46.458400Z"}},"outputs":[],"execution_count":18},{"id":"bd550e11","cell_type":"markdown","source":"---","metadata":{}},{"id":"aafc1a86","cell_type":"code","source":"train = pd.read_csv(\"filtered_data/spam_ham_train.csv\")\nval = pd.read_csv(\"filtered_data/spam_ham_val.csv\")\ntest = pd.read_csv(\"filtered_data/spam_ham_test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T09:52:53.485896Z","iopub.execute_input":"2025-08-07T09:52:53.486636Z","iopub.status.idle":"2025-08-07T09:52:57.461280Z","shell.execute_reply.started":"2025-08-07T09:52:53.486608Z","shell.execute_reply":"2025-08-07T09:52:57.460719Z"}},"outputs":[],"execution_count":19},{"id":"94fb18d0","cell_type":"markdown","source":"## Classifier","metadata":{}},{"id":"8447c5f3","cell_type":"code","source":"model_name = \"bert-base-uncased\" #test cased/uncased\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T09:53:05.474273Z","iopub.execute_input":"2025-08-07T09:53:05.475123Z","iopub.status.idle":"2025-08-07T09:53:13.137965Z","shell.execute_reply.started":"2025-08-07T09:53:05.475089Z","shell.execute_reply":"2025-08-07T09:53:13.137471Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"018d3d657a184aae953ef49abb0f6cd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecb3ed27f5b94b198717caced608e789"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91b8501f5e1d47b79e55f5ca621e2d09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94959d830aba4f098ee787e135f2bc3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d084f2230ea146f69e193ebb0c26a983"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":20},{"id":"1e237773-dd52-48fe-8aa2-fc62dc3918af","cell_type":"code","source":"for name, param in model.base_model.named_parameters():\n    param.requires_grad = False\n\nfor name, param in model.base_model.named_parameters():\n    if \"pooler\" in name:\n        param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:53:15.609611Z","iopub.execute_input":"2025-08-07T09:53:15.610176Z","iopub.status.idle":"2025-08-07T09:53:15.615143Z","shell.execute_reply.started":"2025-08-07T09:53:15.610154Z","shell.execute_reply":"2025-08-07T09:53:15.614447Z"},"trusted":true},"outputs":[],"execution_count":21},{"id":"e1f56dd6-6dcd-431f-9baa-9288b7cc21be","cell_type":"code","source":"reduced_train = train.sample(n=2000, random_state=42)\nreduced_val = val.sample(n=2000, random_state=42)\nreduced_test = test.sample(n=2000, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:53:47.257894Z","iopub.execute_input":"2025-08-07T09:53:47.258599Z","iopub.status.idle":"2025-08-07T09:53:47.269763Z","shell.execute_reply.started":"2025-08-07T09:53:47.258574Z","shell.execute_reply":"2025-08-07T09:53:47.269012Z"},"trusted":true},"outputs":[],"execution_count":23},{"id":"94742e46","cell_type":"code","source":"train_ds = Dataset.from_pandas(reduced_train)\nval_ds = Dataset.from_pandas(reduced_val)\ntest_ds = Dataset.from_pandas(reduced_test)","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:53:52.254055Z","iopub.execute_input":"2025-08-07T09:53:52.254645Z","iopub.status.idle":"2025-08-07T09:53:52.341695Z","shell.execute_reply.started":"2025-08-07T09:53:52.254620Z","shell.execute_reply":"2025-08-07T09:53:52.341125Z"},"trusted":true},"outputs":[],"execution_count":24},{"id":"454bdc57","cell_type":"code","source":"dataset_dict = DatasetDict({\"train\": train_ds, \"val\": val_ds, \"test\": test_ds})","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:53:54.211841Z","iopub.execute_input":"2025-08-07T09:53:54.212333Z","iopub.status.idle":"2025-08-07T09:53:54.215728Z","shell.execute_reply.started":"2025-08-07T09:53:54.212310Z","shell.execute_reply":"2025-08-07T09:53:54.215041Z"},"trusted":true},"outputs":[],"execution_count":25},{"id":"d1093d9b","cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:53:57.636654Z","iopub.execute_input":"2025-08-07T09:53:57.636917Z","iopub.status.idle":"2025-08-07T09:53:57.640883Z","shell.execute_reply.started":"2025-08-07T09:53:57.636898Z","shell.execute_reply":"2025-08-07T09:53:57.640093Z"},"trusted":true},"outputs":[],"execution_count":26},{"id":"28b155d4","cell_type":"code","source":"tokenized_data = dataset_dict.map(preprocess_function, batched=True)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:53:59.468815Z","iopub.execute_input":"2025-08-07T09:53:59.469084Z","iopub.status.idle":"2025-08-07T09:54:03.426936Z","shell.execute_reply.started":"2025-08-07T09:53:59.469065Z","shell.execute_reply":"2025-08-07T09:54:03.426358Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bff2a755ecf349ee913c2e8920501e46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f8f80c2f54e4801a3b90aa831d0802c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"845b87d395854c018be580ec0b1ac934"}},"metadata":{}}],"execution_count":27},{"id":"d47a6f0a","cell_type":"code","source":"accuracy = evaluate.load(\"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:54:06.016756Z","iopub.execute_input":"2025-08-07T09:54:06.017387Z","iopub.status.idle":"2025-08-07T09:54:07.371715Z","shell.execute_reply.started":"2025-08-07T09:54:06.017360Z","shell.execute_reply":"2025-08-07T09:54:07.371175Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6259aa79efc2476eaeec68d8cdf80a4b"}},"metadata":{}}],"execution_count":28},{"id":"ba411e73","cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=1)\n    accuracy_res = accuracy.compute(predictions=predictions, references=labels)\n    return {\"accuracy\" : accuracy_res[\"accuracy\"]}","metadata":{"execution":{"iopub.status.busy":"2025-08-07T09:54:37.848474Z","iopub.execute_input":"2025-08-07T09:54:37.849047Z","iopub.status.idle":"2025-08-07T09:54:37.853604Z","shell.execute_reply.started":"2025-08-07T09:54:37.849023Z","shell.execute_reply":"2025-08-07T09:54:37.853035Z"},"trusted":true},"outputs":[],"execution_count":30},{"id":"aa2ff485","cell_type":"code","source":"lr = 1e-4\nbatch_sz = 32\nepoch = 3\nwd = 0.01\n\ntraining_args = TrainingArguments(\n    output_dir=\"bert-spam-ham-classifier-added-wd\",\n    per_device_train_batch_size=batch_sz,\n    per_device_eval_batch_size=batch_sz,\n    num_train_epochs=epoch,\n    eval_strategy=\"epoch\",\n    logging_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n\n    learning_rate= lr,\n    weight_decay= wd,\n    report_to=\"none\"\n)","metadata":{"execution":{"iopub.status.busy":"2025-08-07T10:10:43.063532Z","iopub.execute_input":"2025-08-07T10:10:43.064268Z","iopub.status.idle":"2025-08-07T10:10:43.091571Z","shell.execute_reply.started":"2025-08-07T10:10:43.064244Z","shell.execute_reply":"2025-08-07T10:10:43.091012Z"},"trusted":true},"outputs":[],"execution_count":41},{"id":"0afa8a23","cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_data[\"train\"],\n    eval_dataset=tokenized_data[\"val\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2025-08-07T10:10:46.378794Z","iopub.execute_input":"2025-08-07T10:10:46.379558Z","iopub.status.idle":"2025-08-07T10:10:46.392841Z","shell.execute_reply.started":"2025-08-07T10:10:46.379532Z","shell.execute_reply":"2025-08-07T10:10:46.392083Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1459056268.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":42},{"id":"25102a1c","cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2025-08-07T10:10:48.328351Z","iopub.execute_input":"2025-08-07T10:10:48.329016Z","iopub.status.idle":"2025-08-07T10:14:04.924908Z","shell.execute_reply.started":"2025-08-07T10:10:48.328982Z","shell.execute_reply":"2025-08-07T10:14:04.924346Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 03:15, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.281700</td>\n      <td>0.275353</td>\n      <td>0.886000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.267600</td>\n      <td>0.257131</td>\n      <td>0.898000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.261400</td>\n      <td>0.254108</td>\n      <td>0.897000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=189, training_loss=0.27021718908239295, metrics={'train_runtime': 196.1396, 'train_samples_per_second': 30.59, 'train_steps_per_second': 0.964, 'total_flos': 1578666332160000.0, 'train_loss': 0.27021718908239295, 'epoch': 3.0})"},"metadata":{}}],"execution_count":43},{"id":"4db755da-6c39-47af-8f11-a6f56c2826bc","cell_type":"code","source":"!pip3 install tqdm==4.62.1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5edd7fec-5edb-44dc-8340-3f5419c8fedd","cell_type":"markdown","source":"### Testing","metadata":{}},{"id":"a8b225b4-d8a6-4ae8-858f-31e3516c32f1","cell_type":"code","source":"test_results = trainer.predict(tokenized_data[\"test\"])","metadata":{"execution":{"iopub.status.busy":"2025-08-07T10:14:17.396478Z","iopub.execute_input":"2025-08-07T10:14:17.397101Z","iopub.status.idle":"2025-08-07T10:14:48.800092Z","shell.execute_reply.started":"2025-08-07T10:14:17.397078Z","shell.execute_reply":"2025-08-07T10:14:48.799545Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":44},{"id":"66109575-0834-4545-8a95-1e58064be163","cell_type":"code","source":"test_results.metrics","metadata":{"execution":{"iopub.status.busy":"2025-08-07T10:14:58.137137Z","iopub.execute_input":"2025-08-07T10:14:58.137430Z","iopub.status.idle":"2025-08-07T10:14:58.142337Z","shell.execute_reply.started":"2025-08-07T10:14:58.137409Z","shell.execute_reply":"2025-08-07T10:14:58.141590Z"},"trusted":true},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"{'test_loss': 0.25653406977653503,\n 'test_accuracy': 0.8955,\n 'test_runtime': 31.395,\n 'test_samples_per_second': 63.704,\n 'test_steps_per_second': 2.007}"},"metadata":{}}],"execution_count":45},{"id":"ffd84aaa-dcc9-4658-8ae6-af5be3c29a7d","cell_type":"markdown","source":"### Testing learning rate","metadata":{}},{"id":"5eee2d44-01bc-4429-9cc7-4705b593bc91","cell_type":"code","source":"results = []\n\nbatch_sz = 32\nepoch = 3\nlearning_rates = [1e-5, 2e-5, 3e-5, 5e-5, 1e-4]\nfor lr in learning_rates:\n    print(f\"Testing learning rate: {lr}\")\n    \n    training_args = TrainingArguments(\n        output_dir=\"bert-spam-ham-classifier-testing-learning-rate\",\n        per_device_train_batch_size=batch_sz,\n        per_device_eval_batch_size=batch_sz,\n        num_train_epochs=epoch,\n        eval_strategy=\"epoch\",\n        logging_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        load_best_model_at_end=True,\n    \n        learning_rate= lr,\n        report_to=\"none\"\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_data[\"train\"],\n        eval_dataset=tokenized_data[\"val\"],\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics\n    )\n\n    trainer.train()\n    test_results = trainer.predict(tokenized_data[\"test\"])\n\n    results.append({\"learning_rate\": lr, \n                    \"loss\": test_results.metrics[\"test_loss\"],\n                   \"accuracy\": test_results.metrics[\"test_accuracy\"]})\n\n\n\nprint(\"----------------------\")\nresults = sorted(results, key=lambda x: x[\"accuracy\"], reverse=True)\nprint(results)\nprint(\"----------------------\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T10:29:33.398915Z","iopub.execute_input":"2025-08-07T10:29:33.399756Z","iopub.status.idle":"2025-08-07T10:48:40.158770Z","shell.execute_reply.started":"2025-08-07T10:29:33.399720Z","shell.execute_reply":"2025-08-07T10:48:40.158027Z"}},"outputs":[{"name":"stdout","text":"Testing learning rate: 1e-05\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3555311632.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 03:17, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.235800</td>\n      <td>0.255498</td>\n      <td>0.897500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.244700</td>\n      <td>0.256383</td>\n      <td>0.895500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.250400</td>\n      <td>0.255051</td>\n      <td>0.897000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Testing learning rate: 2e-05\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3555311632.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 03:16, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.232700</td>\n      <td>0.251936</td>\n      <td>0.897500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.240800</td>\n      <td>0.254264</td>\n      <td>0.896500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.246000</td>\n      <td>0.251237</td>\n      <td>0.897000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Testing learning rate: 3e-05\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3555311632.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 03:17, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.227000</td>\n      <td>0.249671</td>\n      <td>0.899000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.235000</td>\n      <td>0.249984</td>\n      <td>0.898500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.240000</td>\n      <td>0.246640</td>\n      <td>0.899500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Testing learning rate: 5e-05\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3555311632.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 03:17, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.219600</td>\n      <td>0.256017</td>\n      <td>0.897500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.227700</td>\n      <td>0.244093</td>\n      <td>0.901000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.232300</td>\n      <td>0.240670</td>\n      <td>0.902000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Testing learning rate: 0.0001\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3555311632.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 03:16, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.210600</td>\n      <td>0.250301</td>\n      <td>0.897500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.218700</td>\n      <td>0.233723</td>\n      <td>0.905500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.222400</td>\n      <td>0.230673</td>\n      <td>0.905500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"----------------------\n[{'learning_rate': 0.0001, 'loss': 0.2279825359582901, 'accuracy': 0.907}, {'learning_rate': 5e-05, 'loss': 0.23968440294265747, 'accuracy': 0.901}, {'learning_rate': 3e-05, 'loss': 0.24686606228351593, 'accuracy': 0.8965}, {'learning_rate': 2e-05, 'loss': 0.2521768808364868, 'accuracy': 0.8935}, {'learning_rate': 1e-05, 'loss': 0.25644001364707947, 'accuracy': 0.892}]\n----------------------\n","output_type":"stream"}],"execution_count":49},{"id":"732d2ba8-f0c0-40fd-891a-a1d23e9a0674","cell_type":"markdown","source":"### Testing weight decay","metadata":{}},{"id":"40ac6282-97cc-42e7-b709-d768c4657594","cell_type":"code","source":"results = []\nlr = 1e-4\nbatch_sz = 32\nepoch = 3\nweight_decay_values = [0.0, 0.01, 0.05, 0.1, 0.2]\nfor wd in weight_decay_values:\n    print(f\"Testing weight decay: {wd}\")\n    \n    training_args = TrainingArguments(\n        output_dir=\"bert-spam-ham-classifier-testing-learning-rate\",\n        per_device_train_batch_size=batch_sz,\n        per_device_eval_batch_size=batch_sz,\n        num_train_epochs=epoch,\n        eval_strategy=\"epoch\",\n        logging_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        load_best_model_at_end=True,\n    \n        learning_rate= lr,\n        weight_decay=wd,\n        report_to=\"none\"\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_data[\"train\"],\n        eval_dataset=tokenized_data[\"val\"],\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics\n    )\n\n    trainer.train()\n    test_results = trainer.predict(tokenized_data[\"test\"])\n\n    results.append({\"weight_decay\": wd, \n                    \"loss\": test_results.metrics[\"test_loss\"],\n                   \"accuracy\": test_results.metrics[\"test_accuracy\"]})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T11:02:58.029980Z","iopub.execute_input":"2025-08-07T11:02:58.030271Z","iopub.status.idle":"2025-08-07T11:22:06.922635Z","shell.execute_reply.started":"2025-08-07T11:02:58.030250Z","shell.execute_reply":"2025-08-07T11:22:06.922009Z"}},"outputs":[{"name":"stdout","text":"Testing weight decay: 0.0\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/107004643.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 03:17, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.166700</td>\n      <td>0.245472</td>\n      <td>0.901000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.187700</td>\n      <td>0.228023</td>\n      <td>0.906500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.201700</td>\n      <td>0.223830</td>\n      <td>0.909500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Testing weight decay: 0.01\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/107004643.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 03:17, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.155500</td>\n      <td>0.244646</td>\n      <td>0.904000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.180200</td>\n      <td>0.227715</td>\n      <td>0.906500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.197400</td>\n      <td>0.223194</td>\n      <td>0.908000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Testing weight decay: 0.05\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/107004643.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 03:17, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.145300</td>\n      <td>0.244616</td>\n      <td>0.904500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.173500</td>\n      <td>0.227817</td>\n      <td>0.908000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.193900</td>\n      <td>0.222983</td>\n      <td>0.910500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Testing weight decay: 0.1\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/107004643.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 03:17, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.136000</td>\n      <td>0.245436</td>\n      <td>0.904500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.167500</td>\n      <td>0.228250</td>\n      <td>0.909500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.191000</td>\n      <td>0.223126</td>\n      <td>0.911000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Testing weight decay: 0.2\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/107004643.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 03:17, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.127300</td>\n      <td>0.246338</td>\n      <td>0.903000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.161900</td>\n      <td>0.228870</td>\n      <td>0.908000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.188400</td>\n      <td>0.223532</td>\n      <td>0.911500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":52},{"id":"2cbc1039-c8c6-45a9-aa32-f627030cf0a1","cell_type":"code","source":"print(\"----------------------\")\nresults = sorted(results, key=lambda x: x[\"accuracy\"], reverse=True)\nfor res in results:\n    print(res)\nprint(\"----------------------\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T11:22:06.923719Z","iopub.execute_input":"2025-08-07T11:22:06.923915Z","iopub.status.idle":"2025-08-07T11:22:06.928233Z","shell.execute_reply.started":"2025-08-07T11:22:06.923899Z","shell.execute_reply":"2025-08-07T11:22:06.927699Z"}},"outputs":[{"name":"stdout","text":"----------------------\n{'weight_decay': 0.2, 'loss': 0.2106834352016449, 'accuracy': 0.917}\n{'weight_decay': 0.01, 'loss': 0.2132614701986313, 'accuracy': 0.915}\n{'weight_decay': 0.05, 'loss': 0.21186915040016174, 'accuracy': 0.915}\n{'weight_decay': 0.1, 'loss': 0.2110491693019867, 'accuracy': 0.9145}\n{'weight_decay': 0.0, 'loss': 0.21533747017383575, 'accuracy': 0.9135}\n----------------------\n","output_type":"stream"}],"execution_count":53},{"id":"203fbf48-49ff-4cee-9a42-f773812c8c9b","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}