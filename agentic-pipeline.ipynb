{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5042ca72",
   "metadata": {},
   "source": [
    "# Wrapping the Fine-Tuned Model into an Agentic pipeline (LangChain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa26cdff",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf730d77",
   "metadata": {},
   "source": [
    "### Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd0d66",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d42ee8cd",
   "metadata": {
    "execution": {
     "iopub.status.idle": "2025-08-11T09:19:24.385003Z",
     "shell.execute_reply": "2025-08-11T09:19:24.384184Z",
     "shell.execute_reply.started": "2025-08-11T09:19:21.176489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc90810-3530-4275-bb27-c6b72127f0eb",
   "metadata": {
    "execution": {
     "shell.execute_reply": "2025-08-11T09:19:28.856387Z",
     "shell.execute_reply.started": "2025-08-11T09:19:25.745745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e37a8-3a6e-4c9a-9061-667f447f2981",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install -U langchain-huggingface transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287a16e1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1cb6b4f-f55a-4d82-976d-8bff80631073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:19:36.022455Z",
     "iopub.status.busy": "2025-08-11T09:19:36.022151Z",
     "iopub.status.idle": "2025-08-11T09:19:36.114470Z",
     "shell.execute_reply": "2025-08-11T09:19:36.113907Z",
     "shell.execute_reply.started": "2025-08-11T09:19:36.022427Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.26 0.3.74 0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain, langchain_core, langchain_community\n",
    "print(langchain.__version__, langchain_core.__version__, langchain_community.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d55ed53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:59:12.480498Z",
     "iopub.status.busy": "2025-08-11T09:59:12.479916Z",
     "iopub.status.idle": "2025-08-11T09:59:12.484842Z",
     "shell.execute_reply": "2025-08-11T09:59:12.483990Z",
     "shell.execute_reply.started": "2025-08-11T09:59:12.480471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_react_agent, AgentExecutor, create_tool_calling_agent\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_huggingface import HuggingFacePipeline \n",
    "from langchain_huggingface import ChatHuggingFace\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf3325c3-fe91-41f4-a30e-d9617840c6fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:22:26.371510Z",
     "iopub.status.busy": "2025-08-11T09:22:26.370155Z",
     "iopub.status.idle": "2025-08-11T09:22:26.375339Z",
     "shell.execute_reply": "2025-08-11T09:22:26.374632Z",
     "shell.execute_reply.started": "2025-08-11T09:22:26.371477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "device = 0 if use_gpu else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e01e604",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "984b6a7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:43:25.866829Z",
     "iopub.status.busy": "2025-08-11T09:43:25.866449Z",
     "iopub.status.idle": "2025-08-11T09:43:25.870697Z",
     "shell.execute_reply": "2025-08-11T09:43:25.869895Z",
     "shell.execute_reply.started": "2025-08-11T09:43:25.866804Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gen_model_path = \"Qwen/Qwen2.5-1.5B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393737d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:45:08.139480Z",
     "iopub.status.busy": "2025-08-11T09:45:08.139205Z",
     "iopub.status.idle": "2025-08-11T09:45:32.424174Z",
     "shell.execute_reply": "2025-08-11T09:45:32.423033Z",
     "shell.execute_reply.started": "2025-08-11T09:45:08.139463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gen_tok = AutoTokenizer.from_pretrained(gen_model_path)\n",
    "gen_model = AutoModelForCausalLM.from_pretrained(gen_model_path)\n",
    "gen_pipe = pipeline(\"text-generation\",\n",
    "                    model=gen_model, \n",
    "                    tokenizer=gen_tok, \n",
    "                    max_new_tokens=256,\n",
    "                    \n",
    "                    device=device\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d651a59-bd66-404e-83eb-cca6d4c602c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:45:55.353330Z",
     "iopub.status.busy": "2025-08-11T09:45:55.353008Z",
     "iopub.status.idle": "2025-08-11T09:45:56.119278Z",
     "shell.execute_reply": "2025-08-11T09:45:56.118390Z",
     "shell.execute_reply.started": "2025-08-11T09:45:55.353305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "llm = ChatHuggingFace(llm=HuggingFacePipeline(pipeline=gen_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad2e0839-0e78-460a-8062-82ff0c1bfc1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:23:53.193973Z",
     "iopub.status.busy": "2025-08-11T09:23:53.193264Z",
     "iopub.status.idle": "2025-08-11T09:23:56.605769Z",
     "shell.execute_reply": "2025-08-11T09:23:56.604998Z",
     "shell.execute_reply.started": "2025-08-11T09:23:53.193939Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello! hello!'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_pipe(\"hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "387b5dec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:23:58.695070Z",
     "iopub.status.busy": "2025-08-11T09:23:58.694784Z",
     "iopub.status.idle": "2025-08-11T09:23:58.847055Z",
     "shell.execute_reply": "2025-08-11T09:23:58.846444Z",
     "shell.execute_reply.started": "2025-08-11T09:23:58.695051Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classifier_path = \"/kaggle/input/classifier-model/bert-spam-ham-classifier-full_dataset/checkpoint-13086\"\n",
    "cls_model = AutoModelForSequenceClassification.from_pretrained(classifier_path)\n",
    "cls_tokenizer = AutoTokenizer.from_pretrained(classifier_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03edfa29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:24:00.539026Z",
     "iopub.status.busy": "2025-08-11T09:24:00.538728Z",
     "iopub.status.idle": "2025-08-11T09:24:00.699749Z",
     "shell.execute_reply": "2025-08-11T09:24:00.699110Z",
     "shell.execute_reply.started": "2025-08-11T09:24:00.539005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "clf = pipeline(\"text-classification\", \n",
    "               model=cls_model, \n",
    "               tokenizer=cls_tokenizer, \n",
    "               device=device\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb00cb8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:46:31.692267Z",
     "iopub.status.busy": "2025-08-11T09:46:31.691514Z",
     "iopub.status.idle": "2025-08-11T09:46:31.708077Z",
     "shell.execute_reply": "2025-08-11T09:46:31.707467Z",
     "shell.execute_reply.started": "2025-08-11T09:46:31.692237Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.6220700144767761}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf(\"hello click here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7724947d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:24:04.108227Z",
     "iopub.status.busy": "2025-08-11T09:24:04.107937Z",
     "iopub.status.idle": "2025-08-11T09:24:04.115633Z",
     "shell.execute_reply": "2025-08-11T09:24:04.114652Z",
     "shell.execute_reply.started": "2025-08-11T09:24:04.108208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@tool(\"classify_spam_ham\")\n",
    "def classify_spam_ham(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Classify the given message as spam or ham.\n",
    "    \"\"\"\n",
    "    pred = clf(text)[0][\"label\"]\n",
    "    return \"spam\" if pred == \"LABEL_1\" else \"ham\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09689972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:25:28.697417Z",
     "iopub.status.busy": "2025-08-11T09:25:28.696753Z",
     "iopub.status.idle": "2025-08-11T09:25:28.700865Z",
     "shell.execute_reply": "2025-08-11T09:25:28.699880Z",
     "shell.execute_reply.started": "2025-08-11T09:25:28.697393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tools = [classify_spam_ham]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "616798cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:14:25.693852Z",
     "iopub.status.busy": "2025-08-11T10:14:25.693259Z",
     "iopub.status.idle": "2025-08-11T10:14:25.697349Z",
     "shell.execute_reply": "2025-08-11T10:14:25.696552Z",
     "shell.execute_reply.started": "2025-08-11T10:14:25.693828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "system = \"\"\"\n",
    "You are a terminal assistant.\n",
    "\n",
    "RULES:\n",
    "- Only call the tool `classify_spam_ham` if the user EXPLICITLY asks to classify,\n",
    "  OR they use trigger phrases like: \"classify\", \"is this spam\", \"spam or ham\",\n",
    "  \"label this\", \"check for spam\", or the input starts with \"Classify this:\" or \"Classify:\".\n",
    "- If the user sends a greeting or small talk (e.g., \"hello\", \"hi\"), DO NOT call any tool.\n",
    "- When you do call the tool, after it returns, output EXACTLY the tool's result\n",
    "  in lowercase (`spam` or `ham`), with no extra words or punctuation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3056e358",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:02:37.625429Z",
     "iopub.status.busy": "2025-08-11T10:02:37.624941Z",
     "iopub.status.idle": "2025-08-11T10:02:37.629627Z",
     "shell.execute_reply": "2025-08-11T10:02:37.628788Z",
     "shell.execute_reply.started": "2025-08-11T10:02:37.625403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a terminal agent. You can call tools.\\n\\n\"\n",
    "     \"Available tools:\\n{tools}\\n\\nUse exactly: {tool_names}\\n\"\n",
    "     \"If the user pastes a message, prefer classification.\"),\n",
    "    (\"ai\", \"{agent_scratchpad}\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0cd7e8b6-899f-481e-8382-b9547267b470",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:14:27.686507Z",
     "iopub.status.busy": "2025-08-11T10:14:27.685926Z",
     "iopub.status.idle": "2025-08-11T10:14:27.690317Z",
     "shell.execute_reply": "2025-08-11T10:14:27.689632Z",
     "shell.execute_reply.started": "2025-08-11T10:14:27.686485Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    MessagesPlaceholder(\"chat_history\"),      \n",
    "    (\"human\", \"{input}\"),                     \n",
    "    MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe689d8",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#agent = create_react_agent(llm, tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4db8189b-0ec2-4da1-8019-07185b4cfd28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:14:29.544424Z",
     "iopub.status.busy": "2025-08-11T10:14:29.543792Z",
     "iopub.status.idle": "2025-08-11T10:14:29.550381Z",
     "shell.execute_reply": "2025-08-11T10:14:29.549573Z",
     "shell.execute_reply.started": "2025-08-11T10:14:29.544394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9e192446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:14:31.077628Z",
     "iopub.status.busy": "2025-08-11T10:14:31.076550Z",
     "iopub.status.idle": "2025-08-11T10:14:31.081863Z",
     "shell.execute_reply": "2025-08-11T10:14:31.081048Z",
     "shell.execute_reply.started": "2025-08-11T10:14:31.077576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "agent_exec = AgentExecutor(agent=agent, \n",
    "                           tools=tools, \n",
    "                           verbose=True, \n",
    "                           return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e71a560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:14:32.645772Z",
     "iopub.status.busy": "2025-08-11T10:14:32.645511Z",
     "iopub.status.idle": "2025-08-11T10:14:32.815613Z",
     "shell.execute_reply": "2025-08-11T10:14:32.814930Z",
     "shell.execute_reply.started": "2025-08-11T10:14:32.645755Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mspam\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "spam\n"
     ]
    }
   ],
   "source": [
    "res = agent_exec.invoke({\"input\": \"Classify this: You won $10,000! Claim now.\", \"chat_history\": []})\n",
    "print(res[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "66c47c64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T10:15:38.331282Z",
     "iopub.status.busy": "2025-08-11T10:15:38.330517Z",
     "iopub.status.idle": "2025-08-11T10:15:41.125563Z",
     "shell.execute_reply": "2025-08-11T10:15:41.124849Z",
     "shell.execute_reply.started": "2025-08-11T10:15:38.331255Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mMichael Jordan was an American professional basketball player who had an exceptional career. He played for the Chicago Bulls and led them to six NBA championships from 1991 to 1993. Jordan also won three Olympic gold medals as part of the U.S. men's national basketball team. His skills on both ends of the court made him one of the greatest players in the history of basketball.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Michael Jordan was an American professional basketball player who had an exceptional career. He played for the Chicago Bulls and led them to six NBA championships from 1991 to 1993. Jordan also won three Olympic gold medals as part of the U.S. men's national basketball team. His skills on both ends of the court made him one of the greatest players in the history of basketball.\n"
     ]
    }
   ],
   "source": [
    "res = agent_exec.invoke({\"input\": \"Who is Michael Jordan?\", \"chat_history\": []})\n",
    "print(res[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a85e482-7955-42ee-b455-68e22b2fef6a",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832a464-a574-42c7-9f67-66c48679f7af",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8043412,
     "sourceId": 12725625,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
